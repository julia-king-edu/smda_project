{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: center;\" >\n",
    "<h1 style=\"margin-top: 0.2em; margin-bottom: 0.1em;\">Social Media Data Analysis - Final Project</h1>\n",
    "<h4 style=\"margin-top: 0.7em; margin-bottom: 0.3em; font-style:italic\">Data Processing</h2>\n",
    "<h4 style=\"margin-top: 0.7em; margin-bottom: 0.3em; font-style:italic\">Julia King</h4>\n",
    "</div>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\julia\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\julia\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\julia\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# import chunk\n",
    "\n",
    "from common_functions import confirm_execution, read_video_json, read_manual_sample, write_manual_sample, read_video_df, write_video_df, convert_conspirative_to_bool\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from copy import deepcopy\n",
    "\n",
    "# manual sample\n",
    "import random\n",
    "import csv\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# tkinter app\n",
    "import tkinter as tk\n",
    "from tkinter import messagebox\n",
    "import pandas as pd\n",
    "import webbrowser\n",
    "\n",
    "# text cleaning\n",
    "import regex as re\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "nltk.download([\"stopwords\", \"punkt\", \"wordnet\"])\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# models\n",
    "import time\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Based on the title and description, classify a sample of the videos as conspirative or non-conspirative by hand."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function creating sample dataset\n",
    "\n",
    "def sample_videos(video_json: list, n : int = 250, seed : int = 94) -> pd.DataFrame:\n",
    "    # generate docstring by typing \"\"\"\n",
    "    \n",
    "    # get n random videos\n",
    "    random.seed(seed)\n",
    "    vd_sample = random.sample(video_json, k = n)\n",
    "    \n",
    "    # create df\n",
    "    sample = pd.DataFrame(data = {\n",
    "        \"video_id\" : [video[\"video_id\"] for video in vd_sample], \n",
    "        \"title\" : [video[\"metadata\"][\"snippet\"][\"title\"] for video in vd_sample], \n",
    "        \"description\" : [video[\"metadata\"][\"snippet\"][\"description\"] for video in vd_sample], \n",
    "        \"conspirative\" : pd.NA\n",
    "    })\n",
    "    return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "Exception",
     "evalue": "Execution aborted by user.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mException\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# draw training sample\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m confirm_execution(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDo you want to reset the manually evaluated sample?\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      5\u001b[0m manual_sample \u001b[38;5;241m=\u001b[39m sample_videos(video_json, n \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m400\u001b[39m)\n\u001b[0;32m      7\u001b[0m write_manual_sample(manual_sample)\n",
      "File \u001b[1;32mc:\\Users\\julia\\OneDrive\\uni\\12_so-24\\pol_social-media-data-analysis\\project\\common_functions.py:17\u001b[0m, in \u001b[0;36mconfirm_execution\u001b[1;34m(prompt)\u001b[0m\n\u001b[0;32m     14\u001b[0m reset \u001b[38;5;241m=\u001b[39m \u001b[38;5;28minput\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mprompt\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m (yes/anything else): \u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mstrip()\u001b[38;5;241m.\u001b[39mlower()\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m reset \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myes\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m---> 17\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExecution aborted by user.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m\n",
      "\u001b[1;31mException\u001b[0m: Execution aborted by user."
     ]
    }
   ],
   "source": [
    "# draw training sample\n",
    "\n",
    "confirm_execution(\"Do you want to reset the manually evaluated sample?\")\n",
    "\n",
    "manual_sample = sample_videos(video_json, n = 400)\n",
    "\n",
    "write_manual_sample(manual_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create tkinter app for labelling\n",
    "\n",
    "class ConspiracyLabeler:\n",
    "    def __init__(self, root, filepath):\n",
    "        self.root = root\n",
    "        self.filepath = filepath\n",
    "        self.df = read_manual_sample(self.filepath)\n",
    "        self.index = 0\n",
    "        self.prev_index = None\n",
    "\n",
    "        # display how many i still need to label\n",
    "        self.counter_label = tk.Label(root, text = \"\", font = (\"Arial\", 12))\n",
    "        self.counter_label.pack(pady = 10)\n",
    "\n",
    "        # create title display\n",
    "        self.root.title(\"Conspirative Labeler\")\n",
    "        self.title_label = tk.Label(root, text = \"\", font = (\"Arial\", 16))\n",
    "        self.title_label.pack(pady = 10)\n",
    "\n",
    "        # create scrollable description\n",
    "        self.desc_frame = tk.Frame(root)\n",
    "        self.desc_frame.pack(pady = 10, fill = \"both\", expand = True)\n",
    "        self.canvas = tk.Canvas(self.desc_frame, height = 100)  # Set an initial height for the canvas\n",
    "        self.scrollbar = tk.Scrollbar(self.desc_frame, orient = \"vertical\", command = self.canvas.yview)\n",
    "        self.scrollable_frame = tk.Frame(self.canvas)\n",
    "        \n",
    "        self.canvas.configure(yscrollcommand = self.scrollbar.set)\n",
    "        self.scrollbar.pack(side = \"right\", fill = \"y\")\n",
    "        self.canvas.pack(side = \"left\", fill = \"both\", expand = True)\n",
    "        self.canvas.create_window((0, 0), window = self.scrollable_frame, anchor = \"nw\")\n",
    "        self.scrollable_frame.bind(\"<Configure>\", lambda e: self.canvas.configure(scrollregion = self.canvas.bbox(\"all\")))\n",
    "\n",
    "        self.desc_label = tk.Label(self.scrollable_frame, text = \"\", wraplength = 400, justify = \"left\", font = (\"Arial\", 12))\n",
    "        self.desc_label.pack()\n",
    "\n",
    "        # add clickable link\n",
    "        self.link_label = tk.Label(root, text = \"Open video in browser\", fg = \"blue\", cursor = \"hand2\", font = (\"Arial\", 12))\n",
    "        self.link_label.pack(pady = 10)\n",
    "        self.link_label.bind(\"<Button-1>\", self.open_link)\n",
    "        \n",
    "        # other buttons\n",
    "        self.undo_button = tk.Button(root, text = \"Undo\", command = self.undo, width = 10, state = \"disabled\")\n",
    "        self.undo_button.pack(pady = 10)\n",
    "        \n",
    "        self.close_button = tk.Button(root, text = \"Save and Close\", command = self.shutdown, width = 12)\n",
    "        self.close_button.pack(pady = 10)\n",
    "\n",
    "        self.true_button = tk.Button(root, text = \"[c]onspirative\", command = lambda : self.label_conspiracy(True), width = 15)\n",
    "        self.true_button.pack(side = \"left\", padx = 20)\n",
    "\n",
    "        self.false_button = tk.Button(root, text = \"[n]on-conspirative\", command = lambda : self.label_conspiracy(False), width = 15)\n",
    "        self.false_button.pack(side = \"right\", padx = 20)\n",
    "\n",
    "        self.root.bind(\"c\", lambda event : self.label_conspiracy(True))\n",
    "        self.root.bind(\"n\", lambda event : self.label_conspiracy(False))\n",
    "        self.root.bind(\"<Configure>\", self.update_wraplength)\n",
    "\n",
    "        self.next()\n",
    "    \n",
    "    def shutdown(self, completed : bool = False):\n",
    "        \"\"\"Saves current dataframe to file and closes the app.\n",
    "        \n",
    "        Args:\n",
    "            completed (bool): Should be set to true if the shutdown was triggered due to the user finishing the labels.\n",
    "        \"\"\"\n",
    "        write_manual_sample(self.df, filepath = self.filepath)\n",
    "        if (completed):\n",
    "            messagebox.showinfo(\"Finished\", \"All videos have been labelled! \\nThe app will now close.\")\n",
    "        else:\n",
    "            messagebox.showinfo(\"Save successful!\", \"The app will now close. \\nSee you next time!\")\n",
    "        self.root.destroy()\n",
    "\n",
    "    def update_counter(self):\n",
    "        \"\"\"Updates the counter label with the number of labeled and remaining items.\n",
    "        \"\"\"\n",
    "        total_items = len(self.df)\n",
    "        labeled_items = len(self.df.dropna(subset = [\"conspirative\"]))\n",
    "        remaining_items = total_items - labeled_items\n",
    "        self.counter_label.config(text = f\"Labeled: {labeled_items} / Remaining: {remaining_items}\")\n",
    "    \n",
    "    def update_wraplength(self, event):\n",
    "        \"\"\"Updates the wraplength of the description based on the window width. Purely for aesthetics\n",
    "        \"\"\"\n",
    "        new_width = self.canvas.winfo_width() - 20  # padding\n",
    "        self.desc_label.config(wraplength = new_width)\n",
    "\n",
    "    def update_index(self):\n",
    "        \"\"\"Finds the next row without an evaluation and sets the indexes accordingly.\n",
    "        \"\"\"\n",
    "        self.prev_index = self.index\n",
    "        for next_i in range(0, len(self.df)): # could've started the range at self.index as well, but this takes basically no time anyway and is safer.\n",
    "            if (pd.isna(self.df.loc[next_i, \"conspirative\"])):\n",
    "                self.index = next_i\n",
    "                return\n",
    "        self.index = None\n",
    "        return\n",
    "    \n",
    "    def update_display(self):\n",
    "        \"\"\"Update the title and description to evaluate.\n",
    "        \"\"\"\n",
    "        self.title_label.config(text = self.df.loc[self.index, \"title\"])\n",
    "        self.desc_label.config(text = self.df.loc[self.index, \"description\"])\n",
    "        self.update_counter()\n",
    "    \n",
    "    def undo(self):\n",
    "        \"\"\"Undoes the last evaluation & returns to the corresponding row.\n",
    "\n",
    "        Raises:\n",
    "            ValueError: Triggered if no previous index is available.\n",
    "        \"\"\"\n",
    "        if (self.prev_index is None):\n",
    "            raise ValueError(\"Undo was triggered without a previous action. This should not be possible.\")\n",
    "        self.df.at[self.prev_index, \"conspirative\"] = pd.NA\n",
    "        self.index = self.prev_index\n",
    "        self.prev_index = None\n",
    "        self.undo_button[\"state\"] = \"disabled\"\n",
    "        self.update_display()\n",
    "    \n",
    "    def next(self):\n",
    "        \"\"\"Finds & displays the next unevaluated row.\n",
    "        \"\"\"\n",
    "        self.update_index()\n",
    "        self.undo_button[\"state\"] = \"normal\"\n",
    "        if not(self.index is None):\n",
    "            self.update_display()\n",
    "        else:\n",
    "            self.shutdown(completed = True)\n",
    "        return\n",
    "\n",
    "    def label_conspiracy(self, value : bool):\n",
    "        \"\"\"Sets the label according to the pressed button\n",
    "\n",
    "        Args:\n",
    "            value (bool): True if conspirative, False otherwise.\n",
    "        \"\"\"\n",
    "        self.df.at[self.index, \"conspirative\"] = value\n",
    "        self.next()\n",
    "\n",
    "    def open_link(self, event):\n",
    "        \"\"\"Opens the video in a new browser tab\n",
    "\n",
    "        Args:\n",
    "            event (_type_): unused, necessary bc of tkinter\n",
    "        \"\"\"\n",
    "        video_id = self.df.loc[self.index, \"video_id\"]\n",
    "        video_url = f\"https://www.youtube.com/watch?v={video_id}\"\n",
    "        webbrowser.open_new(video_url)\n",
    "\n",
    "def launch_ConspiracyLabeler(filepath : str):\n",
    "    \"\"\"Launches the Conspiracy labeller to manually evaluate the videos.\n",
    "\n",
    "    Args:\n",
    "        filepath (str): relative path to manual sample.\n",
    "    \"\"\"\n",
    "    label_root = tk.Tk()\n",
    "    label_app = ConspiracyLabeler(label_root, filepath = filepath)\n",
    "    label_root.mainloop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# confirm and launch\n",
    "\n",
    "confirm_execution(\"Do you want to launch the labelling tool?\")\n",
    "\n",
    "launch_ConspiracyLabeler(\"data/manual_sample.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Employ supervised text analysis to classify the dataset as conspirative or non-conspirative. Evaluate the performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.1 Create video metadata dataframe\n",
    "\n",
    "This will include all relevant video-level variables. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_json = read_video_json()\n",
    "manual_sample = read_manual_sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "vd_nocomments = [{key : value for key, value in video.items() if key != \"comments\"} for video in video_json]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create function to make/reset video df\n",
    "\n",
    "def create_video_df(video_json : list, manual_sample : pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Creates an initial video dataframe from video_json. \n",
    "\n",
    "    Args:\n",
    "        video_json (list): Obtained in data_collection\n",
    "        manual_sample (pd.DataFrame) : the results of the manual sampling\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: dataframe containing relevant info from video metadata, manual eval results and empty cols for automatic labelling\n",
    "    \"\"\"\n",
    "    \n",
    "    relevant_cols = {\n",
    "        \"phase\": \"phase\", \n",
    "        \"week_start\": \"week_start\", \n",
    "        \"video_id\": \"id\", \n",
    "        \"metadata.snippet.title\": \"title\", \n",
    "        \"metadata.snippet.description\": \"description\", \n",
    "        \"metadata.statistics.viewCount\": \"views\",\n",
    "        \"metadata.statistics.likeCount\": \"likes\", \n",
    "        \"metadata.statistics.commentCount\": \"comments\"\n",
    "    }\n",
    "    \n",
    "    # start with known fields\n",
    "    video_df = pd.json_normalize(vd_nocomments)\n",
    "    video_df = video_df.rename(columns = relevant_cols)\n",
    "    video_df = video_df[[*relevant_cols.values()]]\n",
    "    \n",
    "    # add cols for automatic evaluation\n",
    "    label_cols = [\"conspirative_\" + method for method in [\"manual\", \"nbayes\", \"svm\", \"rforest\"]]\n",
    "    video_df[label_cols] = pd.NA\n",
    "    for col in label_cols:\n",
    "        video_df[col] = pd.to_numeric(video_df[col], errors = \"coerce\")\n",
    "        video_df[col] = video_df[col].astype(\"boolean\")\n",
    "    \n",
    "    # add manual sample results\n",
    "    video_df[\"conspirative_manual\"] = pd.merge(left = video_df, right = manual_sample[[\"video_id\", \"conspirative\"]], left_on = \"id\", right_on = \"video_id\", how = \"left\")[\"conspirative\"]\n",
    "\n",
    "    # make id the index\n",
    "    video_df = video_df.set_index(\"id\")\n",
    "    \n",
    "    return video_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create/reset video df\n",
    "\n",
    "confirm_execution(\"Do you want to reset the video df? All automatic labels will be lost.\")\n",
    "\n",
    "video_df = create_video_df(video_json, manual_sample)\n",
    "\n",
    "write_video_df(video_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.2 text preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_df = read_video_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for preprocessing with subfunctions for individual processing\n",
    "\n",
    "def clean_string(text : str) -> str:\n",
    "    \"\"\"if the text argument is a string, removes links & all non alpha-numeric characters, tokenizes, lemmatizes, and removes stopwords\n",
    "\n",
    "    Args:\n",
    "        text (str): string, ideally containing multiple words\n",
    "\n",
    "    Returns:\n",
    "        str: cleaned string\n",
    "    \"\"\"\n",
    "    if type(text) != str:\n",
    "        return text\n",
    "    \n",
    "    # remove links\n",
    "    text = re.sub(r\"https?://\\S+|www\\.\\S+\", \" \", text)\n",
    "    \n",
    "    # remove newline\n",
    "    text = re.sub(r\"\\n\", \" \", text)\n",
    "    \n",
    "    # remove everything except alphabetical and numerical characters\n",
    "    text = re.sub(\"[^a-zA-Z0-9]\", \" \", text)\n",
    "    \n",
    "    # tokenize & lemmatize\n",
    "    text = nltk.word_tokenize(text.lower())\n",
    "    lemma = WordNetLemmatizer()\n",
    "    text = [lemma.lemmatize(word) for word in text]\n",
    "    \n",
    "    # remove stopwords\n",
    "    stopwords = nltk.corpus.stopwords.words(\"english\")\n",
    "    text = [word for word in text if word not in stopwords]\n",
    "    \n",
    "    # join together again\n",
    "    text = \" \".join(text)\n",
    "\n",
    "    return text\n",
    "\n",
    "def clean_cols(df : pd.DataFrame) -> pd.Series:\n",
    "    \"\"\"takes all columns in data frames, combines their content into a single string and cleans them\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): df to apply clean_string to\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: series containing the cleaned version of the combined texts\n",
    "    \"\"\"\n",
    "    \n",
    "    # create copy so original is not unintentionally overwritten\n",
    "    df_copy = deepcopy(df)\n",
    "    df_copy = df_copy.astype(str)\n",
    "\n",
    "    texts = df_copy.agg(' '.join, axis = 1)\n",
    "    \n",
    "    return texts.apply(lambda text : clean_string(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>phase</th>\n",
       "      <th>week_start</th>\n",
       "      <th>title</th>\n",
       "      <th>description</th>\n",
       "      <th>views</th>\n",
       "      <th>clean</th>\n",
       "      <th>likes</th>\n",
       "      <th>comments</th>\n",
       "      <th>conspirative_manual</th>\n",
       "      <th>conspirative_nbayes</th>\n",
       "      <th>conspirative_svm</th>\n",
       "      <th>conspirative_rforest</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Gg38BtcNioY</th>\n",
       "      <td>0</td>\n",
       "      <td>2022-03-20</td>\n",
       "      <td>The Office of Community Development! 15-Minute...</td>\n",
       "      <td>🛣️Watch the next episode: https://youtu.be/Vd2...</td>\n",
       "      <td>991</td>\n",
       "      <td>office community development 15 minute city 10...</td>\n",
       "      <td>100.0</td>\n",
       "      <td>64</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ne6nrlB_3os</th>\n",
       "      <td>0</td>\n",
       "      <td>2022-03-20</td>\n",
       "      <td>URBTalk: 20 Minute Neighbourhood</td>\n",
       "      <td>URBTalk presentation on the 20 minute neighbou...</td>\n",
       "      <td>166</td>\n",
       "      <td>urbtalk 20 minute neighbourhood urbtalk presen...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2mezuB5BwnA</th>\n",
       "      <td>0</td>\n",
       "      <td>2022-03-20</td>\n",
       "      <td>Expo 2020 Dubai Will Reopen As A 15-Minute Cit...</td>\n",
       "      <td>.</td>\n",
       "      <td>114</td>\n",
       "      <td>expo 2020 dubai reopen 15 minute city 10 pavil...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             phase  week_start  \\\n",
       "id                               \n",
       "Gg38BtcNioY      0  2022-03-20   \n",
       "Ne6nrlB_3os      0  2022-03-20   \n",
       "2mezuB5BwnA      0  2022-03-20   \n",
       "\n",
       "                                                         title  \\\n",
       "id                                                               \n",
       "Gg38BtcNioY  The Office of Community Development! 15-Minute...   \n",
       "Ne6nrlB_3os                   URBTalk: 20 Minute Neighbourhood   \n",
       "2mezuB5BwnA  Expo 2020 Dubai Will Reopen As A 15-Minute Cit...   \n",
       "\n",
       "                                                   description  views  \\\n",
       "id                                                                      \n",
       "Gg38BtcNioY  🛣️Watch the next episode: https://youtu.be/Vd2...    991   \n",
       "Ne6nrlB_3os  URBTalk presentation on the 20 minute neighbou...    166   \n",
       "2mezuB5BwnA                                                  .    114   \n",
       "\n",
       "                                                         clean  likes  \\\n",
       "id                                                                      \n",
       "Gg38BtcNioY  office community development 15 minute city 10...  100.0   \n",
       "Ne6nrlB_3os  urbtalk 20 minute neighbourhood urbtalk presen...    1.0   \n",
       "2mezuB5BwnA  expo 2020 dubai reopen 15 minute city 10 pavil...    0.0   \n",
       "\n",
       "             comments  conspirative_manual  conspirative_nbayes  \\\n",
       "id                                                                \n",
       "Gg38BtcNioY        64                 <NA>                 <NA>   \n",
       "Ne6nrlB_3os         0                 <NA>                 <NA>   \n",
       "2mezuB5BwnA         0                 <NA>                 <NA>   \n",
       "\n",
       "             conspirative_svm  conspirative_rforest  \n",
       "id                                                   \n",
       "Gg38BtcNioY              <NA>                  <NA>  \n",
       "Ne6nrlB_3os              <NA>                  <NA>  \n",
       "2mezuB5BwnA              <NA>                  <NA>  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# apply cleaning function\n",
    "\n",
    "video_df[\"clean\"] = clean_cols(video_df[[\"title\", \"description\"]])\n",
    "\n",
    "# reorder\n",
    "cols = list(video_df.columns)\n",
    "cols.remove(\"clean\")\n",
    "cols.insert(5, \"clean\")\n",
    "video_df = video_df[cols]\n",
    "\n",
    "video_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function that returns bag of words for given df\n",
    "\n",
    "def get_bow(df : pd.DataFrame, text_col : str = \"clean\") -> pd.DataFrame:\n",
    "    # generate docstring by typing \"\"\"\n",
    "    vectorizer = CountVectorizer(min_df = 5) # setting a minimum number of appearances to keep outliers out\n",
    "\n",
    "    # get bag of words\n",
    "    vectorizer.fit(df[text_col])\n",
    "    bow_matrix = vectorizer.transform(df[text_col])\n",
    "    bow_df = pd.DataFrame(bow_matrix.toarray(), index = df.index, columns = vectorizer.get_feature_names_out()) # convert to df and replace indexes with video id and word name\n",
    "    \n",
    "    # sort the df by the row sums in descending order\n",
    "    bow_df = bow_df = bow_df[bow_df.sum(axis = 0).sort_values(ascending=False).index]\n",
    "    return bow_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>city</th>\n",
       "      <th>minute</th>\n",
       "      <th>15</th>\n",
       "      <th>video</th>\n",
       "      <th>de</th>\n",
       "      <th>channel</th>\n",
       "      <th>urban</th>\n",
       "      <th>like</th>\n",
       "      <th>use</th>\n",
       "      <th>nan</th>\n",
       "      <th>...</th>\n",
       "      <th>selection</th>\n",
       "      <th>buzz</th>\n",
       "      <th>monitored</th>\n",
       "      <th>buymeacoffee</th>\n",
       "      <th>alley</th>\n",
       "      <th>extend</th>\n",
       "      <th>sensory</th>\n",
       "      <th>monetary</th>\n",
       "      <th>integrate</th>\n",
       "      <th>belong</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Gg38BtcNioY</th>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ne6nrlB_3os</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2mezuB5BwnA</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 4204 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             city  minute  15  video  de  channel  urban  like  use  nan  ...  \\\n",
       "id                                                                        ...   \n",
       "Gg38BtcNioY     6       2   2      1   0        1      0     2    2    0  ...   \n",
       "Ne6nrlB_3os     0       2   0      0   0        0      0     0    0    0  ...   \n",
       "2mezuB5BwnA     1       1   1      0   0        0      0     0    0    0  ...   \n",
       "\n",
       "             selection  buzz  monitored  buymeacoffee  alley  extend  sensory  \\\n",
       "id                                                                              \n",
       "Gg38BtcNioY          0     0          0             0      0       0        0   \n",
       "Ne6nrlB_3os          0     0          0             0      0       0        0   \n",
       "2mezuB5BwnA          0     0          0             0      0       0        0   \n",
       "\n",
       "             monetary  integrate  belong  \n",
       "id                                        \n",
       "Gg38BtcNioY         0          0       0  \n",
       "Ne6nrlB_3os         0          0       0  \n",
       "2mezuB5BwnA         0          0       0  \n",
       "\n",
       "[3 rows x 4204 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get bow for entire df\n",
    "\n",
    "video_bow = get_bow(video_df)\n",
    "\n",
    "video_bow.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.3 prepare train and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>city</th>\n",
       "      <th>minute</th>\n",
       "      <th>15</th>\n",
       "      <th>video</th>\n",
       "      <th>de</th>\n",
       "      <th>like</th>\n",
       "      <th>use</th>\n",
       "      <th>channel</th>\n",
       "      <th>urban</th>\n",
       "      <th>news</th>\n",
       "      <th>...</th>\n",
       "      <th>larryskylines</th>\n",
       "      <th>edited</th>\n",
       "      <th>pollution</th>\n",
       "      <th>small</th>\n",
       "      <th>order</th>\n",
       "      <th>dystopia</th>\n",
       "      <th>transportation</th>\n",
       "      <th>break</th>\n",
       "      <th>training</th>\n",
       "      <th>committed</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Vd2RawW6HAE</th>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>orpZAEIzIWc</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bsuC9nkhxm0</th>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 743 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             city  minute  15  video  de  like  use  channel  urban  news  \\\n",
       "id                                                                          \n",
       "Vd2RawW6HAE     7       2   2      0   0     2    2        0      0     0   \n",
       "orpZAEIzIWc     0       3   0      1   0     1    2        0      0     0   \n",
       "bsuC9nkhxm0     4       3   3      1   0     1    0        0      0     0   \n",
       "\n",
       "             ...  larryskylines  edited  pollution  small  order  dystopia  \\\n",
       "id           ...                                                             \n",
       "Vd2RawW6HAE  ...              1       0          0      0      0         0   \n",
       "orpZAEIzIWc  ...              0       0          0      0      0         0   \n",
       "bsuC9nkhxm0  ...              0       0          0      0      0         0   \n",
       "\n",
       "             transportation  break  training  committed  \n",
       "id                                                       \n",
       "Vd2RawW6HAE               0      0         0          0  \n",
       "orpZAEIzIWc               0      0         1          0  \n",
       "bsuC9nkhxm0               0      0         0          0  \n",
       "\n",
       "[3 rows x 743 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# extract manually sampled videos & set up train-test-split\n",
    "\n",
    "manual_df = video_df.dropna(subset = [\"conspirative_manual\"])\n",
    "manual_bow = get_bow(manual_df)\n",
    "\n",
    "manual_bow.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up train test split\n",
    "\n",
    "train_x, test_x, train_y, test_y = train_test_split(manual_bow, manual_df[\"conspirative_manual\"], test_size = 0.25, random_state = 94)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare df containing the test set\n",
    "test_df = manual_df.loc[test_x.index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.4 model training & prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# naive bayes\n",
    "nbayes = GaussianNB()\n",
    "nbayes.fit(train_x, train_y)\n",
    "\n",
    "test_df[\"conspirative_nbayes\"] = nbayes.predict(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# survey vector machine\n",
    "svm = SVC()\n",
    "svm.fit(train_x, train_y)\n",
    "\n",
    "test_df[\"conspirative_svm\"] = svm.predict(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# random forest\n",
    "rforest = RandomForestClassifier()\n",
    "rforest.fit(train_x, train_y)\n",
    "\n",
    "test_df[\"conspirative_rforest\"]  = rforest.predict(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>phase</th>\n",
       "      <th>week_start</th>\n",
       "      <th>title</th>\n",
       "      <th>description</th>\n",
       "      <th>views</th>\n",
       "      <th>clean</th>\n",
       "      <th>likes</th>\n",
       "      <th>comments</th>\n",
       "      <th>conspirative_manual</th>\n",
       "      <th>conspirative_nbayes</th>\n",
       "      <th>conspirative_svm</th>\n",
       "      <th>conspirative_rforest</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>zXhZ3_rxv4g</th>\n",
       "      <td>1</td>\n",
       "      <td>2023-02-12</td>\n",
       "      <td>15 Minute Cities | Report from Tiger Mountain</td>\n",
       "      <td>In this Report, Richard discusses the globalis...</td>\n",
       "      <td>289</td>\n",
       "      <td>15 minute city report tiger mountain report ri...</td>\n",
       "      <td>15.0</td>\n",
       "      <td>6</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2gUumw1q6d0</th>\n",
       "      <td>1</td>\n",
       "      <td>2023-02-19</td>\n",
       "      <td>Manifestación Oxford  contra las ciudades de 1...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2612</td>\n",
       "      <td>manifestaci n oxford contra la ciudades de 15 ...</td>\n",
       "      <td>94.0</td>\n",
       "      <td>7</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B9OjtFp3dsc</th>\n",
       "      <td>1</td>\n",
       "      <td>2023-01-22</td>\n",
       "      <td>\"SUSTAINABLE DEVELOPMENT\" 15 MINUTE CITIES wit...</td>\n",
       "      <td>According to the website https://www.15minutec...</td>\n",
       "      <td>749</td>\n",
       "      <td>sustainable development 15 minute city big joh...</td>\n",
       "      <td>56.0</td>\n",
       "      <td>10</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             phase  week_start  \\\n",
       "id                               \n",
       "zXhZ3_rxv4g      1  2023-02-12   \n",
       "2gUumw1q6d0      1  2023-02-19   \n",
       "B9OjtFp3dsc      1  2023-01-22   \n",
       "\n",
       "                                                         title  \\\n",
       "id                                                               \n",
       "zXhZ3_rxv4g      15 Minute Cities | Report from Tiger Mountain   \n",
       "2gUumw1q6d0  Manifestación Oxford  contra las ciudades de 1...   \n",
       "B9OjtFp3dsc  \"SUSTAINABLE DEVELOPMENT\" 15 MINUTE CITIES wit...   \n",
       "\n",
       "                                                   description  views  \\\n",
       "id                                                                      \n",
       "zXhZ3_rxv4g  In this Report, Richard discusses the globalis...    289   \n",
       "2gUumw1q6d0                                                NaN   2612   \n",
       "B9OjtFp3dsc  According to the website https://www.15minutec...    749   \n",
       "\n",
       "                                                         clean  likes  \\\n",
       "id                                                                      \n",
       "zXhZ3_rxv4g  15 minute city report tiger mountain report ri...   15.0   \n",
       "2gUumw1q6d0  manifestaci n oxford contra la ciudades de 15 ...   94.0   \n",
       "B9OjtFp3dsc  sustainable development 15 minute city big joh...   56.0   \n",
       "\n",
       "             comments  conspirative_manual  conspirative_nbayes  \\\n",
       "id                                                                \n",
       "zXhZ3_rxv4g         6                 True                False   \n",
       "2gUumw1q6d0         7                False                 True   \n",
       "B9OjtFp3dsc        10                 True                 True   \n",
       "\n",
       "             conspirative_svm  conspirative_rforest  \n",
       "id                                                   \n",
       "zXhZ3_rxv4g              True                  True  \n",
       "2gUumw1q6d0              True                 False  \n",
       "B9OjtFp3dsc              True                  True  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert 1 to true and 0 to false\n",
    "\n",
    "test_df = convert_conspirative_to_bool(test_df)\n",
    "\n",
    "test_df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.5 Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Use the emotion classification model LEIA to obtain the sentiments expressed in the comments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
